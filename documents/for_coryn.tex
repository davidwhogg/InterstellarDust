% This document is part of the Dust project.
% Copyright 2014 David W. Hogg (NYU)

\documentclass[12pt, letterpaper]{article}

% math
\newcommand{\dd}{\mathrm{d}}
\newcommand{\given}{\,|\,}
\newcommand{\setof}[1]{\left\{{#1}\right\}}
\newcommand{\inverse}[1]{{#1}^{-1}}
\newcommand{\transpose}[1]{{#1}^{\mathsf{T}}}
\renewcommand{\det}[1]{||{#1}||}

\begin{document}

\section{Prior pdfs}

Imagine that we are trying to infer the dust density $\rho(x)$, where
$\rho$ is a continuous function of three-dimensional position $x$.
We will ignore velocity space for now!
Imagine that our prior belief is that the dust density $\rho(x)$ is a
stochastic function that can be generated (approximately) by a
Gaussian with some sensible mean function $\mu_\rho(x)$ and some variance
tensor $K_\rho(x, x')$.
The variance tensor acts on pairs of three-space positions.
It is a ``tensor'' because when it is applied to $N$ three-space
positions $x_n$, it generates for each pair of positions $(n, n')$ the
element $K_{nn'}$ of a $N\times N$ covariance matrix.
The fact that $\rho(x)$ is infinite dimensional---that is, it is
defined as a continuous function in three-space---is a detail; if it
makes you upset, imagine that $x$ can only take on values on a very
fine, finite grid.

This prior belief---that the dust density is drawn from a
Gaussian---is sensible, because it is easily manipulated and computed.
That said, this prior belief is insane, because it allows for
\emph{negative} dust.
There is no way to remove the support of the Gaussian on the
non-fully-positive part of the space (and this is the vast majority of
the space).
We could go to a Gaussian in the \emph{logarithm} of the density, but
this will break the linearity we are going to use (below).

Now think about the fact that we only ever observe the extinction
$A(x)$ at some sparse set of three-dimensional positions $x$; we never
directly observe the density $\rho(x)$.
Following the Bailer-Jones notation, extinctions and densities are
related by
\begin{eqnarray}
A(x) &=& \kappa\,|x|\,\int_0^1 \rho(\eta\,x)\,\dd\eta
\\
\rho(x) &=& \frac{1}{\kappa\,|x|}\,\left.\frac{\dd}{\dd\eta}A(\eta\,x)\right|_{\eta=1}
\quad,
\end{eqnarray}
where $\kappa$ is a constant that relates dust density to extinction
in the relevant band, $\eta$ is a dimensionless integration variable,
and the $|x|$ factors keep the dimensions right.
Recall that $x$ is a three-vector position.

If it is our prior belief about $\rho(x)$ that it is drawn from a
Gaussian with mean $\mu_\rho(x)$ and variance tensor $K_\rho(x, x')$ then I
\emph{believe} that the consistent prior belief about $A(x)$ is that
it is drawn from a Gaussian with mean $\mu_A(x)$ and variance tensor
$K_A(x, x')$ with
\begin{eqnarray}
\mu_A(x) &=& \kappa\,|x|\,\int_0^1 \mu_\rho(\eta\,x)\,\dd\eta
\\
K_A(x_1, x_2) &=& \kappa^2\,|x_1|\,|x_2|\,\int_0^1\int_0^1 K_\rho(\eta_1\,x_1, \eta_2\,x_2)\,\dd\eta_1\,\dd\eta_2
\quad .
\end{eqnarray}
That is, a Gaussian process in $\rho(x)$ implies a Gaussian process in
$A(x)$.

\section{Likelihood}

Imagine we have $N$ observations (from here on: ``data'') $A_n$ at
positions $x_n$ with independent noise contributions.
Each noise contribution is drawn from a Gaussian with mean zero and
variance $\sigma^2_n$.
For now, let's presume that the positions $x_n$ are perfectly known
(more on this later).
Now, how does inference of $A(x)$ and $\rho(x)$ proceed?

The prior on the dust field $\rho(x)$ and extinction field $A(x)$ are
both Gaussian, and the noise is Gaussian, so the marginalized
likelihood---the probability of the data, marginalizing out the
(latent) dust density field or extinction field---is also a Gaussian:
\begin{eqnarray}
\ln p(A\given\mu,K) &=& -\frac{N}{2}\,\ln 2\pi - \frac{1}{2}\,\ln\det{V} - \frac{1}{2}\,\transpose{[A-\mu]}\,\inverse{V}\,[A-\mu]
\\
V &=& K + C
\\
\mu_n &=& \mu_A(x_n)
\\
K_{nn'} &=& K_A(x_n, x_{n'})
\\
C_{nn'} &=& \sigma^2_n\,\delta_{nn'}
\quad ,
\end{eqnarray}

...Notes about computation of this -- the double integrals and the linear algebra

\section{Posterior pdfs}

...posterior for some new $A(x)$

...posterior for some $\rho(x)$

...Some notes on computational efficiency of incremental predictions

\section{Mean, kernel, and hyper-parameters}

...form for the mean function $\mu_\rho(x)$

...form for the kernel function

...Is there any form for the kernel function such that any of the integrals is analytic or simple?

...how to infer the hyperparameters; duh!

\section{Open issues}

...Is there any chance that making the dust density on a grid would help?

...Would discretization help, especially if $N$ is large?

...What to do about distance errors?

...What to do about \emph{improving} distance estimates?

...The kernel functions might be smooth, but they won't be isotropic and homogeneous in either space, right?

\end{document}
